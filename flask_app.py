import numpy as np
from flask import Flask, request, jsonify
from PIL import Image
import io
import tensorflow as tf # Required for loading the model structure

app = Flask(__name__)

# ----------------------------------------------
# 1. SETUP AND CONSTANTS
# ----------------------------------------------
MODEL_PATH = 'FINAL_API_MODEL.h5' 
IMAGE_SIZE = (416, 416)
CLASS_NAMES = [
    'Corroded battery Terminals', 
    'Oil Leak', 
    'Low tire pressure', 
    'Healthy Battery', 
    'Healthy Engine', 
    'Healthy Tire'
] 

# 2. ØªØ­Ù…ÙŠÙ„ Ø§Ù„Ù†Ù…ÙˆØ°Ø¬
try:
    # ğŸ’¡ Ù†Ù‚ÙˆÙ… Ø¨ØªØ­Ù…ÙŠÙ„ Ø§Ù„Ù†Ù…ÙˆØ°Ø¬ Ù…Ø±Ø© ÙˆØ§Ø­Ø¯Ø©
    MODEL = tf.keras.models.load_model(MODEL_PATH)
except Exception as e:
    # Ù‡Ø°Ø§ Ø§Ù„Ø®Ø·Ø£ Ù‡Ùˆ Ø³Ø¨Ø¨ Ø§Ù„Ù…Ø´Ø§ÙƒÙ„ Ø§Ù„Ø³Ø§Ø¨Ù‚Ø©ØŒ ÙˆÙŠØ¬Ø¨ Ø§Ù„ØªØ¹Ø§Ù…Ù„ Ù…Ø¹Ù‡ Ù‡Ù†Ø§
    print(f"FATAL ERROR: Could not load Keras model: {e}")
    # Ø¥Ø°Ø§ ÙØ´Ù„ Ø§Ù„ØªØ­Ù…ÙŠÙ„ØŒ Ù„Ù† Ù†Ù‚ÙˆÙ… Ø¨ØªØ´ØºÙŠÙ„ Ø§Ù„ØªØ·Ø¨ÙŠÙ‚
    MODEL = None

# ----------------------------------------------
# 3. ÙˆØ¸ÙŠÙØ© Ù…Ø¹Ø§Ù„Ø¬Ø© Ø§Ù„ØµÙˆØ±Ø©
# ----------------------------------------------
def preprocess_image(image_file_bytes):
    if MODEL is None:
        return None
        
    image = Image.open(io.BytesIO(image_file_bytes)).convert('RGB')
    image = image.resize(IMAGE_SIZE)
    
    input_data = np.asarray(image, dtype=np.float32)
    input_data = input_data / 255.0
    
    input_data = np.expand_dims(input_data, axis=0)
    return input_data

# ----------------------------------------------
# 4. Ù†Ù‚Ø·Ø© Ø§Ù„Ù†Ù‡Ø§ÙŠØ© Ù„Ù„Ø°ÙƒØ§Ø¡ Ø§Ù„Ø§ØµØ·Ù†Ø§Ø¹ÙŠ (API Endpoint)
# ----------------------------------------------
@app.route('/predict_fault', methods=['POST'])
def predict():
    if MODEL is None:
        return jsonify({'success': False, 'message': 'AI Model is not loaded on the server.'}), 500
        
    if 'image' not in request.files:
        return jsonify({'success': False, 'message': 'No image file provided in the request'}), 400
    
    try:
        image_file = request.files['image'].read()
        processed_image = preprocess_image(image_file)
        
        # Ø¥Ø¬Ø±Ø§Ø¡ Ø§Ù„ØªÙ†Ø¨Ø¤
        predictions = MODEL.predict(processed_image, verbose=0)[0]
        predicted_index = np.argmax(predictions)
        
        # ğŸ”¥ğŸ”¥ Ø§Ù„Ø­Ù„ Ø§Ù„Ø­Ø§Ø³Ù…: Ø§Ù„ØªØ­ÙˆÙŠÙ„ Ø¥Ù„Ù‰ float Ù‚ÙŠØ§Ø³ÙŠ Ù‚Ø¨Ù„ Ø§Ù„Ø¥Ø±Ø³Ø§Ù„ ğŸ”¥ğŸ”¥
        confidence_score = float(np.max(predictions)) 

        # ğŸ’¡ ÙŠØ¬Ø¨ Ø£Ù† ÙŠÙƒÙˆÙ† Ø§Ù„Ø±Ø¯ JSON ÙÙ‚Ø· (String, int, float)
        return jsonify({
            'success': True,
            'fault_class': CLASS_NAMES[predicted_index],
            'confidence': confidence_score
        })
        
    except Exception as e:
        # Ø¥Ø°Ø§ Ø­Ø¯Ø« Ø£ÙŠ Ø®Ø·Ø£ Ø¨Ø±Ù…Ø¬ÙŠØŒ Ù†Ø¹Ø±Ø¶Ù‡ ÙÙŠ Ø§Ù„Ø³Ø¬Ù„
        return jsonify({'success': False, 'message': f'Prediction processing failed: {str(e)}'}), 500


@app.route("/", methods=["GET"])
def home():
    return jsonify({"status": "AI Server Operational (Waiting for POST on /predict_fault)"})
